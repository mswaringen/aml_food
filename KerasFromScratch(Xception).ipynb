{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasFromScratch(Xception).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOnhq34AB8nrza++QRB29Xj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mswaringen/aml_food/blob/master/KerasFromScratch(Xception).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxcnQ59fvNe4"
      },
      "source": [
        "Based on https://keras.io/examples/vision/image_classification_from_scratch/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxbsBtg4vRu-"
      },
      "source": [
        "from keras.models import Sequential\n",
        "#Import from keras_preprocessing not from keras.preprocessing\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers, optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXcSx-FXvYMf"
      },
      "source": [
        "# download and unzip locally\n",
        "\n",
        "downzip=True\n",
        "\n",
        "if downzip:\n",
        "  !mkdir data\n",
        "  %cd data\n",
        "  !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Io_dwM_UujedpHWjRvMpZQ5mtOoeGTDV' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1Io_dwM_UujedpHWjRvMpZQ5mtOoeGTDV\" -O final-project-food-recognition-challenge.zip && rm -rf /tmp/cookies.txt\n",
        "  !unzip final-project-food-recognition-challenge.zip\n",
        "  %cd ..\n",
        "  !mkdir outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7qJXNoHvf4r"
      },
      "source": [
        "traindf = pd.read_csv('data/train_labels.csv',dtype=str)\n",
        "testdf = pd.read_csv('data/sample.csv',dtype=str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5Wx5nO1vhkq"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255.,validation_split=0.20)\n",
        "batch_size = 32\n",
        "image_size = (224,224)\n",
        "\n",
        "\n",
        "train_generator=datagen.flow_from_dataframe(\n",
        "dataframe=traindf,\n",
        "directory=\"data/train_set/train_set/\",\n",
        "x_col=\"img_name\",\n",
        "y_col=\"label\",\n",
        "subset=\"training\",\n",
        "batch_size=batch_size,\n",
        "seed=42,\n",
        "shuffle=True,\n",
        "class_mode=\"categorical\",\n",
        "target_size=image_size)\n",
        "\n",
        "valid_generator=datagen.flow_from_dataframe(\n",
        "dataframe=traindf,\n",
        "directory=\"data/train_set/train_set/\",\n",
        "x_col=\"img_name\",\n",
        "y_col=\"label\",\n",
        "subset=\"validation\",\n",
        "batch_size=batch_size,\n",
        "seed=42,\n",
        "shuffle=True,\n",
        "class_mode=\"categorical\",\n",
        "target_size=image_size)\n",
        "\n",
        "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "test_generator=test_datagen.flow_from_dataframe(\n",
        "dataframe=testdf,\n",
        "directory=\"data/test_set/test_set/\",\n",
        "x_col=\"img_name\",\n",
        "y_col=\"label\",\n",
        "batch_size=1,\n",
        "seed=42,\n",
        "shuffle=False,\n",
        "class_mode=None,\n",
        "target_size=image_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxGMiZmbvqRQ"
      },
      "source": [
        "def make_model(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    # Image augmentation block\n",
        "    x = data_augmentation(inputs)\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for size in [128, 256, 512, 728]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    if num_classes == 2:\n",
        "        activation = \"sigmoid\"\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = \"softmax\"\n",
        "        units = num_classes\n",
        "\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(units, activation=activation)(x)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "model = make_model(input_shape=image_size + (3,), num_classes=80)\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzda5Rx2vxpU"
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\",verbose=1,save_best_only=True),\n",
        "]\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-3),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "history = model.fit(\n",
        "    train_generator, epochs=epochs, callbacks=callbacks, validation_data=valid_generator,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9axahKCwXAf"
      },
      "source": [
        "model.evaluate(valid_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT7CuYkYwjoY"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_acc_loss(history):\n",
        "    fig = plt.figure(figsize=(10,5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        " \n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper right')\n",
        "    plt.show()\n",
        " \n",
        "plot_acc_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}