{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Another2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN81aIxpJOwc02CJWbwt2tX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mswaringen/aml_food/blob/master/Another2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5DX2tQrnUY-"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_xqkJh4mm0U",
        "outputId": "738d736f-c298-4af7-ecb8-6cfcd6292a6c"
      },
      "source": [
        "# download and unzip locally\n",
        "\n",
        "downzip=True\n",
        "\n",
        "if downzip:\n",
        "  !mkdir data\n",
        "  %cd data\n",
        "  !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Io_dwM_UujedpHWjRvMpZQ5mtOoeGTDV' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1Io_dwM_UujedpHWjRvMpZQ5mtOoeGTDV\" -O final-project-food-recognition-challenge.zip && rm -rf /tmp/cookies.txt\n",
        "  !unzip final-project-food-recognition-challenge.zip\n",
        "  %cd ..\n",
        "  !mkdir outputs"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "/content/data\n",
            "--2020-12-04 13:44:20--  https://docs.google.com/uc?export=download&confirm=d_W7&id=1Io_dwM_UujedpHWjRvMpZQ5mtOoeGTDV\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.164.142, 2607:f8b0:4004:802::200e\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.164.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-44-docs.googleusercontent.com/docs/securesc/43sha4if7gjvh82bqc37nlug84mccbn2/mo6jgv1tddqjli25rptlal0j367sfnro/1607089425000/10490392775048702533/13588050619538677717Z/1Io_dwM_UujedpHWjRvMpZQ5mtOoeGTDV?e=download [following]\n",
            "--2020-12-04 13:44:20--  https://doc-04-44-docs.googleusercontent.com/docs/securesc/43sha4if7gjvh82bqc37nlug84mccbn2/mo6jgv1tddqjli25rptlal0j367sfnro/1607089425000/10490392775048702533/13588050619538677717Z/1Io_dwM_UujedpHWjRvMpZQ5mtOoeGTDV?e=download\n",
            "Resolving doc-04-44-docs.googleusercontent.com (doc-04-44-docs.googleusercontent.com)... 172.217.7.161, 2607:f8b0:4004:800::2001\n",
            "Connecting to doc-04-44-docs.googleusercontent.com (doc-04-44-docs.googleusercontent.com)|172.217.7.161|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=mm4inj3m4usta&continue=https://doc-04-44-docs.googleusercontent.com/docs/securesc/43sha4if7gjvh82bqc37nlug84mccbn2/mo6jgv1tddqjli25rptlal0j367sfnro/1607089425000/10490392775048702533/13588050619538677717Z/1Io_dwM_UujedpHWjRvMpZQ5mtOoeGTDV?e%3Ddownload&hash=b79v5e7lhvjbttr85nn3liignrg0qrec [following]\n",
            "--2020-12-04 13:44:20--  https://docs.google.com/nonceSigner?nonce=mm4inj3m4usta&continue=https://doc-04-44-docs.googleusercontent.com/docs/securesc/43sha4if7gjvh82bqc37nlug84mccbn2/mo6jgv1tddqjli25rptlal0j367sfnro/1607089425000/10490392775048702533/13588050619538677717Z/1Io_dwM_UujedpHWjRvMpZQ5mtOoeGTDV?e%3Ddownload&hash=b79v5e7lhvjbttr85nn3liignrg0qrec\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.164.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-04-44-docs.googleusercontent.com/docs/securesc/43sha4if7gjvh82bqc37nlug84mccbn2/mo6jgv1tddqjli25rptlal0j367sfnro/1607089425000/10490392775048702533/13588050619538677717Z/1Io_dwM_UujedpHWjRvMpZQ5mtOoeGTDV?e=download&nonce=mm4inj3m4usta&user=13588050619538677717Z&hash=2a585ha0itft9eprhi7ag9hf0ap7butt [following]\n",
            "--2020-12-04 13:44:20--  https://doc-04-44-docs.googleusercontent.com/docs/securesc/43sha4if7gjvh82bqc37nlug84mccbn2/mo6jgv1tddqjli25rptlal0j367sfnro/1607089425000/10490392775048702533/13588050619538677717Z/1Io_dwM_UujedpHWjRvMpZQ5mtOoeGTDV?e=download&nonce=mm4inj3m4usta&user=13588050619538677717Z&hash=2a585ha0itft9eprhi7ag9hf0ap7butt\n",
            "Connecting to doc-04-44-docs.googleusercontent.com (doc-04-44-docs.googleusercontent.com)|172.217.7.161|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-zip-compressed]\n",
            "Saving to: ‘final-project-food-recognition-challenge.zip’\n",
            "\n",
            "final-project-food-     [              <=>   ] 698.78M   152MB/s    in 4.7s    \n",
            "\n",
            "2020-12-04 13:44:25 (149 MB/s) - ‘final-project-food-recognition-challenge.zip’ saved [732726876]\n",
            "\n",
            "Archive:  final-project-food-recognition-challenge.zip\n",
            "replace sample.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: /content\n",
            "mkdir: cannot create directory ‘outputs’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4auy9pL4m93_"
      },
      "source": [
        "class CatsAndDogsDataset(Dataset):\n",
        "    def __init__(self, root_dir, annotation_file, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.annotations = pd.read_csv(annotation_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_id = self.annotations.iloc[index, 0]\n",
        "        img = Image.open(os.path.join(self.root_dir, img_id)).convert(\"RGB\")\n",
        "        y_label = torch.tensor(float(self.annotations.iloc[index, 1]))\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return (img, y_label)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfZHMkfbnDXw"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, train_CNN=False, num_classes=1):\n",
        "        super(CNN, self).__init__()\n",
        "        self.train_CNN = train_CNN\n",
        "        self.inception = models.inception_v3(pretrained=True, aux_logits=False)\n",
        "        self.inception.fc = nn.Linear(self.inception.fc.in_features, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, images):\n",
        "        features = self.inception(images)\n",
        "        return self.sigmoid(self.dropout(self.relu(features))).squeeze(1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C79IVISnJp5"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((356, 356)),\n",
        "            transforms.RandomCrop((299, 299)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnNet5SbnRC4"
      },
      "source": [
        "# num_epochs = 6\n",
        "learning_rate = 0.00001\n",
        "train_CNN = False\n",
        "batch_size = 512\n",
        "shuffle = True\n",
        "pin_memory = True\n",
        "num_workers = 1\n",
        "\n",
        "dataset = CatsAndDogsDataset(\"data/train_set/train_set\",\"data/train_labels.csv\",transform=transform)\n",
        "\n",
        "train_size = int(len(dataset) * 0.8)\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_set, validation_set = torch.utils.data.random_split(dataset,[train_size,val_size])\n",
        "trainloader = DataLoader(dataset=train_set, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers,pin_memory=pin_memory)\n",
        "testloader = DataLoader(dataset=validation_set, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers, pin_memory=pin_memory)\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTn14NwkoafD"
      },
      "source": [
        "model = CNN().to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for name, param in model.inception.named_parameters():\n",
        "    if \"fc.weight\" in name or \"fc.bias\" in name:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = train_CNN"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "PAop2lNK2hYN",
        "outputId": "17052a3c-5d01-45a7-a91a-6d728da69411"
      },
      "source": [
        "epochs = 1\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "print_every = 10\n",
        "train_losses, test_losses = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for inputs, labels in trainloader:\n",
        "        steps += 1\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logps = model.forward(inputs)\n",
        "        loss = criterion(logps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if steps % print_every == 0:\n",
        "            test_loss = 0\n",
        "            accuracy = 0\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in testloader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    logps = model.forward(inputs)\n",
        "                    batch_loss = criterion(logps, labels)\n",
        "                    test_loss += batch_loss.item()\n",
        "                    \n",
        "                    ps = torch.exp(logps)\n",
        "                    top_p, top_class = ps.topk(1, dim=1)\n",
        "                    equals = top_class == labels.view(*top_class.shape)\n",
        "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "            train_losses.append(running_loss/len(trainloader))\n",
        "            test_losses.append(test_loss/len(testloader))                    \n",
        "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
        "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
        "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
        "            running_loss = 0\n",
        "            model.train()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-7341d603dbd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                     \u001b[0mtop_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                     \u001b[0mequals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtop_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0maccuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HwR456f3TaH"
      },
      "source": [
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(test_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQbCYAwB_19v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}